#!/usr/bin/env python3
"""
BFCL í‰ê°€ ìë™í™” ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
    # í€µ í…ŒìŠ¤íŠ¸ (ê° ì¹´í…Œê³ ë¦¬ 2ê°œì”©)
    python run_eval.py --quick
    
    # íŠ¹ì • ëª¨ë¸ë§Œ í€µ í…ŒìŠ¤íŠ¸
    python run_eval.py --quick --models openrouter/qwen3-14b-FC
    
    # ì „ì²´ í…ŒìŠ¤íŠ¸
    python run_eval.py --full
    
    # íŠ¹ì • ì¹´í…Œê³ ë¦¬ë§Œ
    python run_eval.py --quick --categories simple_python,multiple

ê²°ê³¼ë¬¼:
    reports/
    â”œâ”€â”€ {model_name}/
    â”‚   â””â”€â”€ {model_name}_eval_report.xlsx
    â””â”€â”€ summary/
        â””â”€â”€ all_models_summary.xlsx
"""

import argparse
import json
import os
import shutil
import subprocess
import sys
from datetime import datetime
from pathlib import Path

# ì§€ì› ëª¨ë¸ ëª©ë¡
SUPPORTED_MODELS = [
    "openrouter/llama-3.3-70b-instruct-FC",
    "openrouter/mistral-small-3.2-24b-instruct-FC",
    "openrouter/qwen3-32b-FC",
    "openrouter/qwen3-14b-FC",
    "openrouter/qwen3-next-80b-a3b-instruct-FC",
]

# í€µ í…ŒìŠ¤íŠ¸ìš© ID (ê° ì¹´í…Œê³ ë¦¬ 2ê°œì”©)
QUICK_TEST_IDS = {
    "simple_python": ["simple_python_0", "simple_python_1"],
    "multiple": ["multiple_0", "multiple_1"],
    "parallel": ["parallel_0", "parallel_1"],
}

# ì „ì²´ ì¹´í…Œê³ ë¦¬
ALL_CATEGORIES = ["simple_python", "multiple", "parallel"]


def run_command(cmd: list, description: str = "") -> bool:
    """ëª…ë ¹ ì‹¤í–‰"""
    if description:
        print(f"\n{'='*60}")
        print(f"ğŸ“Œ {description}")
        print(f"{'='*60}")
    
    print(f"$ {' '.join(cmd)}")
    result = subprocess.run(cmd, capture_output=False)
    return result.returncode == 0


def clean_directories():
    """ì´ì „ ê²°ê³¼ ì •ë¦¬"""
    print("\nğŸ§¹ ì´ì „ ê²°ê³¼ ì •ë¦¬ ì¤‘...")
    for dir_name in ["result", "score"]:
        dir_path = Path(dir_name)
        if dir_path.exists():
            shutil.rmtree(dir_path)
        dir_path.mkdir(parents=True, exist_ok=True)
    print("âœ… ì •ë¦¬ ì™„ë£Œ")


def setup_quick_test():
    """í€µ í…ŒìŠ¤íŠ¸ ì„¤ì • íŒŒì¼ ìƒì„±"""
    test_ids_file = Path("test_case_ids_to_generate.json")
    with open(test_ids_file, "w") as f:
        json.dump(QUICK_TEST_IDS, f, indent=2)
    print(f"âœ… í€µ í…ŒìŠ¤íŠ¸ ì„¤ì • ì™„ë£Œ: {test_ids_file}")


def generate_results(model: str, categories: list, is_quick: bool) -> bool:
    """ëª¨ë¸ ì‘ë‹µ ìƒì„±"""
    cmd = [
        "python", "-m", "bfcl_eval", "generate",
        "--model", model,
        "--test-category", ",".join(categories),
        "--temperature", "0",
        "--num-threads", "1",
    ]
    
    if is_quick:
        cmd.append("--run-ids")
    
    return run_command(cmd, f"ì‘ë‹µ ìƒì„±: {model}")


def evaluate_results(models: list, categories: list) -> bool:
    """í‰ê°€ ì‹¤í–‰"""
    cmd = [
        "python", "-m", "bfcl_eval", "evaluate",
        "--model", ",".join(models),
        "--test-category", ",".join(categories),
        "--partial-eval",
    ]
    
    return run_command(cmd, "í‰ê°€ ì‹¤í–‰")


def generate_reports(models: list):
    """ì—‘ì…€ ë³´ê³ ì„œ ìƒì„±"""
    from excel_reporter import generate_excel_report, generate_all_models_summary
    
    reports_dir = Path("reports")
    reports_dir.mkdir(exist_ok=True)
    
    print(f"\n{'='*60}")
    print("ğŸ“Š ì—‘ì…€ ë³´ê³ ì„œ ìƒì„±")
    print(f"{'='*60}")
    
    # ëª¨ë¸ë³„ ë³´ê³ ì„œ ìƒì„±
    model_reports = []
    
    for model in models:
        safe_name = model.replace("/", "_")
        result_dir = Path(f"result/{safe_name}")
        score_dir = Path(f"score/{safe_name}")
        
        if not result_dir.exists():
            print(f"âš ï¸  ê²°ê³¼ ì—†ìŒ: {model}")
            continue
        
        # ëª¨ë¸ë³„ í´ë” ìƒì„±
        model_report_dir = reports_dir / safe_name
        model_report_dir.mkdir(exist_ok=True)
        
        # ë³´ê³ ì„œ ìƒì„±
        try:
            report_path = generate_excel_report(
                model_name=model,
                result_dir=str(result_dir),
                score_dir=str(score_dir)
            )
            
            # ìƒì„±ëœ íŒŒì¼ì„ ëª¨ë¸ í´ë”ë¡œ ì´ë™
            report_file = Path(report_path)
            target_path = model_report_dir / f"{safe_name}_eval_report.xlsx"
            if report_file.exists():
                shutil.move(str(report_file), str(target_path))
                print(f"âœ… {model}: {target_path}")
                model_reports.append(target_path)
        except Exception as e:
            print(f"âŒ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨ ({model}): {e}")
    
    # ì „ì²´ ì·¨í•© ë³´ê³ ì„œ ìƒì„±
    if len(model_reports) > 1:
        try:
            summary_path = generate_all_models_summary(str(reports_dir))
            print(f"âœ… ì „ì²´ ì·¨í•©: {summary_path}")
        except Exception as e:
            print(f"âš ï¸  ì·¨í•© ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}")
    
    return model_reports


def print_summary(models: list):
    """ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
    print(f"\n{'='*60}")
    print("ğŸ“‹ í‰ê°€ ê²°ê³¼ ìš”ì•½")
    print(f"{'='*60}")
    
    # score íŒŒì¼ì—ì„œ ê²°ê³¼ ì½ê¸°
    for model in models:
        safe_name = model.replace("/", "_")
        score_dir = Path(f"score/{safe_name}/non_live")
        
        if not score_dir.exists():
            continue
        
        print(f"\nğŸ¦ {model}")
        
        for score_file in sorted(score_dir.glob("*_score.json")):
            with open(score_file) as f:
                first_line = f.readline()
                summary = json.loads(first_line)
            
            category = score_file.name.replace("BFCL_v4_", "").replace("_score.json", "")
            accuracy = summary.get("accuracy", 0) * 100
            correct = summary.get("correct_count", 0)
            total = summary.get("total_count", 0)
            
            status = "âœ…" if accuracy >= 80 else "âš ï¸" if accuracy >= 50 else "âŒ"
            print(f"   {status} {category}: {accuracy:.1f}% ({correct}/{total})")


def main():
    parser = argparse.ArgumentParser(description="BFCL í‰ê°€ ìë™í™”")
    parser.add_argument("--quick", action="store_true", help="í€µ í…ŒìŠ¤íŠ¸ (ê° ì¹´í…Œê³ ë¦¬ 2ê°œì”©)")
    parser.add_argument("--full", action="store_true", help="ì „ì²´ í…ŒìŠ¤íŠ¸")
    parser.add_argument("--models", type=str, help="í…ŒìŠ¤íŠ¸í•  ëª¨ë¸ (ì‰¼í‘œ êµ¬ë¶„)")
    parser.add_argument("--categories", type=str, help="í…ŒìŠ¤íŠ¸í•  ì¹´í…Œê³ ë¦¬ (ì‰¼í‘œ êµ¬ë¶„)")
    parser.add_argument("--skip-generate", action="store_true", help="ìƒì„± ë‹¨ê³„ ê±´ë„ˆë›°ê¸°")
    parser.add_argument("--skip-evaluate", action="store_true", help="í‰ê°€ ë‹¨ê³„ ê±´ë„ˆë›°ê¸°")
    parser.add_argument("--report-only", action="store_true", help="ë³´ê³ ì„œë§Œ ìƒì„±")
    
    args = parser.parse_args()
    
    # ê¸°ë³¸ê°’: í€µ í…ŒìŠ¤íŠ¸
    if not args.quick and not args.full:
        args.quick = True
    
    # ëª¨ë¸ ëª©ë¡
    if args.models:
        models = [m.strip() for m in args.models.split(",")]
    else:
        models = SUPPORTED_MODELS
    
    # ì¹´í…Œê³ ë¦¬ ëª©ë¡
    if args.categories:
        categories = [c.strip() for c in args.categories.split(",")]
    else:
        categories = ALL_CATEGORIES
    
    print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    BFCL í‰ê°€ ìë™í™”                          â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  ëª¨ë“œ: {'í€µ í…ŒìŠ¤íŠ¸' if args.quick else 'ì „ì²´ í…ŒìŠ¤íŠ¸'}                                          â•‘
â•‘  ëª¨ë¸: {len(models)}ê°œ                                                â•‘
â•‘  ì¹´í…Œê³ ë¦¬: {', '.join(categories):<43} â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")
    
    # 1. ì •ë¦¬
    if not args.report_only and not args.skip_generate:
        clean_directories()
        
        if args.quick:
            setup_quick_test()
    
    # 2. ìƒì„±
    if not args.report_only and not args.skip_generate:
        for model in models:
            if not generate_results(model, categories, args.quick):
                print(f"âŒ ìƒì„± ì‹¤íŒ¨: {model}")
    
    # 3. í‰ê°€
    if not args.report_only and not args.skip_evaluate:
        if not evaluate_results(models, categories):
            print("âŒ í‰ê°€ ì‹¤íŒ¨")
    
    # 4. ë³´ê³ ì„œ ìƒì„±
    generate_reports(models)
    
    # 5. ìš”ì•½ ì¶œë ¥
    print_summary(models)
    
    print(f"\n{'='*60}")
    print("ğŸ‰ ì™„ë£Œ!")
    print(f"{'='*60}")
    print(f"ğŸ“ ë³´ê³ ì„œ ìœ„ì¹˜: reports/")


if __name__ == "__main__":
    main()
